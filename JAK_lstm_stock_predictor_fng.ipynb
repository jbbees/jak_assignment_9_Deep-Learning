{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Fear and Greed Index\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin fear and greed index values to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous fng values\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 0\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30, 15, 40, 24, 11,  8, 36, 30, 44, 54],\n",
       "       [15, 40, 24, 11,  8, 36, 30, 44, 54, 31],\n",
       "       [40, 24, 11,  8, 36, 30, 44, 54, 31, 42],\n",
       "       [24, 11,  8, 36, 30, 44, 54, 31, 42, 35],\n",
       "       [11,  8, 36, 30, 44, 54, 31, 42, 35, 55],\n",
       "       [ 8, 36, 30, 44, 54, 31, 42, 35, 55, 71],\n",
       "       [36, 30, 44, 54, 31, 42, 35, 55, 71, 67],\n",
       "       [30, 44, 54, 31, 42, 35, 55, 71, 67, 74],\n",
       "       [44, 54, 31, 42, 35, 55, 71, 67, 74, 63],\n",
       "       [54, 31, 42, 35, 55, 71, 67, 74, 63, 67]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "# YOUR CODE HERE!\n",
    "split = int(0.7 * len(X))     # this defines the split of 70% of the entire length of the X data. X has 532 datapoints, so the first 372 datapoints will be assigned to training.                             \n",
    "X_train = X[: split]          # this takes the whole X dataset (532 datapoints) from index numbers 0-371 and assigns to the training. It applies the split at index number 372, so anything from that index is not included in the training.\n",
    "X_test = X[split: ]           # Any X data from index number 372 and onward is assigned to test.      \n",
    "y_train = y[: split]\n",
    "y_test = y[split : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Creating 4 MinMaxScaler() objects. Previously our RNN model code only created 1 in our class examples. \n",
    "X_train_scaler = MinMaxScaler()\n",
    "X_test_scaler = MinMaxScaler()\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_test_scaler = MinMaxScaler()\n",
    "\n",
    "# fitting the train data\n",
    "X_train_scaler.fit(X_train)                               # fit each scaler objects with the appropriate X,y train/test datasets\n",
    "y_train_scaler.fit(y_train)\n",
    "X_test_scaler.fit(X_test)\n",
    "y_test_scaler.fit(y_test)\n",
    "\n",
    "# transform train data\n",
    "X_train = X_train_scaler.transform(X_train)               # transform each X.y dataset into normalized values between 0-1. assign our scaler objects that are fitted with the raw dataset, and transform is run on those values. \n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "X_test = X_test_scaler.transform(X_test)\n",
    "y_test = y_test_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.30379747]\n",
      "  [0.37974684]\n",
      "  [0.27848101]\n",
      "  [0.40506329]\n",
      "  [0.40506329]\n",
      "  [0.34177215]\n",
      "  [0.34177215]\n",
      "  [0.3164557 ]\n",
      "  [0.27848101]\n",
      "  [0.59493671]]\n",
      "\n",
      " [[0.37974684]\n",
      "  [0.27848101]\n",
      "  [0.40506329]\n",
      "  [0.40506329]\n",
      "  [0.34177215]\n",
      "  [0.34177215]\n",
      "  [0.3164557 ]\n",
      "  [0.27848101]\n",
      "  [0.59493671]\n",
      "  [0.62025316]]\n",
      "\n",
      " [[0.27848101]\n",
      "  [0.40506329]\n",
      "  [0.40506329]\n",
      "  [0.34177215]\n",
      "  [0.34177215]\n",
      "  [0.3164557 ]\n",
      "  [0.27848101]\n",
      "  [0.59493671]\n",
      "  [0.62025316]\n",
      "  [0.5443038 ]]\n",
      "\n",
      " [[0.40506329]\n",
      "  [0.40506329]\n",
      "  [0.34177215]\n",
      "  [0.34177215]\n",
      "  [0.3164557 ]\n",
      "  [0.27848101]\n",
      "  [0.59493671]\n",
      "  [0.62025316]\n",
      "  [0.5443038 ]\n",
      "  [0.5443038 ]]\n",
      "\n",
      " [[0.40506329]\n",
      "  [0.34177215]\n",
      "  [0.34177215]\n",
      "  [0.3164557 ]\n",
      "  [0.27848101]\n",
      "  [0.59493671]\n",
      "  [0.62025316]\n",
      "  [0.5443038 ]\n",
      "  [0.5443038 ]\n",
      "  [0.56962025]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "# YOUR CODE HERE!\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))   \n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(X_test[:5])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "model = Sequential ()                            # build the RNN model\n",
    "\n",
    "\n",
    "number_units = 30                                \n",
    "dropout_fraction = 0.2                           # set the dropout rate to 20%, so after running through each layer, it keeps 80% of the data.\n",
    "                                                     # Dropout fraction gives a % chance that a neuron won't be included during testing. In this case, there's a 20% chance each neuron won't be included in testing. \n",
    "\n",
    "# layer 1\n",
    "\n",
    "model.add(LSTM(                                  # Define layer as LSTM\n",
    "    units = number_units,\n",
    "    return_sequences =  True,                    # return sequences to link this LSTM layer to the next\n",
    "    input_shape = (X_train.shape[1], 1)          # X_train.shape[1] is number of time steps, 10 days worth of prices. The second 1 is number of input features it will use to predict 11th day price. \n",
    "))\n",
    "\n",
    "model.add(Dropout(dropout_fraction))             # add first dropout layer. A dropout layer gives a % chance that a neuron won't be included in testing in next LSTM layer. defers to the dropout_fraction, which is 20% \n",
    "                                                 # dropout layers don't have params to pass, no weights in a dropout layer.    \n",
    "                                                 # if there wasn't enough to describe the model in this layer, it won't drop anything. \n",
    "\n",
    "# layer 2\n",
    "\n",
    "model.add(LSTM(                                  # We have our second LSTM layer, but this time all we need is the units and return_sequences param\n",
    "     units = number_units,\n",
    "     return_sequences = True                      # We have another layer to this model, will need a return_sequences =True\n",
    "))\n",
    "\n",
    "model.add(Dropout(dropout_fraction))             # 2nd dropout layer\n",
    "\n",
    "# layer 3\n",
    "\n",
    "model.add(LSTM(units=number_units))               # only need units param in 3rd layer, no other LSTM layers to connect.\n",
    "\n",
    "model.add(Dropout(dropout_fraction))              # final dropout layer before final output layer\n",
    "\n",
    "# output layer \n",
    "model.add(Dense(1))                               # Dense output layer that should return only 1 value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE!\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "# YOUR CODE HERE!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODER'S NOTE:**\n",
    "\n",
    "This summary indicates we do not have enough data to describe our model.\n",
    "\n",
    "* Total params is 18,511\n",
    "* At the first LSTM layer we start with 3,840 params.\n",
    "* The first dropout is zero. This means the model decided 3840 params wasn't enough to describe the model, so it didn't drop anything.\n",
    "* At the second LSTM layer it increased the params to 7320\n",
    "* The next dropout is zero. Not even 7320 was enough to describe the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "372/372 [==============================] - 7s 5ms/step - loss: 0.0322A:\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0340\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0352\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0352\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0351\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0349\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0351\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0336\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0364\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1badf52c908>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "\n",
    "# CODER'S NOTE: not good loss function here. We start at .0322 but loss function increased to .0434."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 2ms/step - loss: 0.2044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20438039302825928"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# YOUR CODE HERE!\n",
    "model.evaluate(X_test, y_test)                       # not really a good model. We want loss function to be close to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "# YOUR CODE HERE!\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = y_test_scaler.inverse_transform(predicted)\n",
    "real_prices = y_test_scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>9772.139648</td>\n",
       "      <td>4066.885010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>9882.429688</td>\n",
       "      <td>4230.646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>9847.450195</td>\n",
       "      <td>4088.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>9478.320313</td>\n",
       "      <td>4054.185059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>9531.769531</td>\n",
       "      <td>3950.745850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Real    Predicted\n",
       "2019-07-25  9772.139648  4066.885010\n",
       "2019-07-26  9882.429688  4230.646484\n",
       "2019-07-27  9847.450195  4088.820312\n",
       "2019-07-28  9478.320313  4054.185059\n",
       "2019-07-29  9531.769531  3950.745850"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='2343'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"fda60cc3-ae13-493d-ae90-88b043bcc130\" data-root-id=\"2343\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"bd04279c-3440-41a4-b074-6fec693c2688\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"2412\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"2371\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"2382\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"2384\",\"type\":\"AllLabels\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"2402\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"2391\"}]},\"id\":\"2416\",\"type\":\"LegendItem\"},{\"attributes\":{\"children\":[{\"id\":\"2344\"},{\"id\":\"2349\"},{\"id\":\"2668\"}],\"margin\":[0,0,0,0],\"name\":\"Row02982\",\"tags\":[\"embedded\"]},\"id\":\"2343\",\"type\":\"Row\"},{\"attributes\":{\"data_source\":{\"id\":\"2418\"},\"glyph\":{\"id\":\"2421\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"2423\"},\"nonselection_glyph\":{\"id\":\"2422\"},\"selection_glyph\":{\"id\":\"2451\"},\"view\":{\"id\":\"2425\"}},\"id\":\"2424\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"2379\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"data\":{\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"vCL433qorkBmxAWgGQyvQCHn/X8Uwq5A3gn2Xw8fr0C+MQQAFzWwQGS1+X89d61ARN0HIAULrkCcSgaAwtOtQCP2CaBw7a1AZLX5f73erUB3RfC/9e6tQFZe8j/hBa5AqqENwJ7IrUDdCfZfjyatQAIPDCBcRK5Ad0Xwv/VFrkAg2PFfOFWuQIm6D0AKOK5AvCL433rXrkCHqwMgrrOuQOEnDqDHRa5A/vDz3yNhrkBWXvI/4UyuQFZe8j/hUq5AQs77/yiurkBE3QcgBXavQAAAAAAAPK9AyogLQLMpr0DgJw6gR3CvQAAAAACAsa9AAg8MINw5r0CHqwMgrkGvQN8YAoBrTq9AH9jxXzg0r0BmxAWgGamuQCP2CaBwzK5Ad0Xwv/Wbr0CaO/pf5oivQE4lA0BhD7BATiUDQCEWsEArL/mfsBCwQHpU/N9RN7BAhqsDIO4qs0C+MQQAl3CzQAtI+x9cMbNAvSL43zq3s0ABAAAAQMGzQELO+/8oUbRAvjEEABeutEAtPgXATFG0QGXEBaCZxrRA1dAGYI+4s0AAAAAAgNmzQELO+/+o2LNAvjEEAJcttEBE3QcgRa2zQNXQBmDPXLRAm0oGgEJ0tED/////v6m0QOlg/Z+Hr7RAhasDIC7OtEBktfl/vbm0QN8YAoCrErVAZcQFoBmjtUAh5/1/lE61QN8YAoCrKrRAvjEEABdytEC8Ivjfem20QNPB+j9zmLRAbwwBwPV1tED1twTgo+a0QJHz/j+KDbVAF58CYLh8tUBOJQNAYXm2QCHn/X8U0LZA9bcE4COitkDfGAKAK3S2QHlU/N+Ru7ZAbwwBwLVut0BvDAHA9Ru4QJHz/j9K1rhACkj7H1wXvEBPJQNAoUG7QApI+x9cfr5ATSUDQCEsv0Ah5/1/1Pe/QApI+x8cwr5AbgwBwPXLvEAh5/1/FGK8QHpU/N+RAMBAkfP+P0o+v0CHqwMg7gu/QPa3BODjyr1A/////3/EvkCaO/pfZjy/QE4lA0Ahe79A3xgCgB0LwUBvDAHAlSjBQLLa/L9sB8FA6WD9n0fswEAAAAAAICrAQG8MAcBVs8BAWW3+X++1wEAh5/1/9BDBQGS1+X99sr9AF58CYHj9vUCR8/4/Sm++QApI+x9cf75ATiUDQKFCv0DpYP2fx/2+QCsv+Z9w271AAAAAAABVv0B5VPzfUe2+QPa3BOAj7r9AvjEEAMkVwEA4hgDg+vrAQOlg/Z/HSsFAvjEEAJeJwUBOJQNAATzCQDiGAODavMFAyHn/H0UgwkCy2vy/bKDCQFlt/l9v9cNAyHn/H8XgxECy2vy//jPFQLLa/L/ejcVA3xgCgCvuxkB7VPzfozjJQN8YAoALycVA6WD9n4chyECy2vy/DDbHQBefAmCGCMVAWW3+X++vxECnkgGgEC7FQIarAyDOZsdAIef9f0LKxUAAAAAAoHjFQBefAmB4+MVAelT83yNpxkAg5/1/FATIQCHn/X+Ci8hAWW3+X4+hx0Babf5fjyfGQFlt/l+vCsdAhqsDIPwxxkAh5/1/NO7DQE4lA0AhMcVAF58CYLhnwkBOJQNAE/DCQLLa/L8sx8RAF58CYHiSxEBwDAHAtQPFQDiGAOBarcRAWW3+X+8qxEBOJQNAEz/DQHpU/N8RFsNAvjEEADdNw0DqYP2fuTvDQL4xBAApg8JAIef9f+KdwkA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]}},\"selected\":{\"id\":\"2386\"},\"selection_policy\":{\"id\":\"2412\"}},\"id\":\"2385\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02987\",\"sizing_mode\":\"stretch_width\"},\"id\":\"2668\",\"type\":\"Spacer\"},{\"attributes\":{\"source\":{\"id\":\"2418\"}},\"id\":\"2425\",\"type\":\"CDSView\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"2401\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02986\",\"sizing_mode\":\"stretch_width\"},\"id\":\"2344\",\"type\":\"Spacer\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2388\",\"type\":\"Line\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"2400\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"2400\"},{\"id\":\"2401\"},{\"id\":\"2402\"},{\"id\":\"2403\"},{\"id\":\"2404\"},{\"id\":\"2405\"},{\"id\":\"2406\"},{\"id\":\"2407\"},{\"id\":\"2408\"},{\"id\":\"2409\"},{\"id\":\"2410\"},{\"id\":\"2411\"}]},\"id\":\"2359\",\"type\":\"DatetimeTicker\"},{\"attributes\":{},\"id\":\"2366\",\"type\":\"SaveTool\"},{\"attributes\":{\"text\":\"Actual vs Predicted Bitcoin Prices Fear and Greed\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"2350\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"2367\",\"type\":\"PanTool\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2390\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2451\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"2370\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"2381\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"2368\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"2411\",\"type\":\"YearsTicker\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2417\",\"type\":\"Line\"},{\"attributes\":{\"overlay\":{\"id\":\"2371\"}},\"id\":\"2369\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"2354\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"2385\"}},\"id\":\"2392\",\"type\":\"CDSView\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"2405\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"2419\",\"type\":\"Selection\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{index}\":\"datetime\"},\"renderers\":[{\"id\":\"2391\"},{\"id\":\"2424\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"index\",\"@{index}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"2347\",\"type\":\"HoverTool\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"2424\"}]},\"id\":\"2450\",\"type\":\"LegendItem\"},{\"attributes\":{\"axis_label\":\"Monthly Progression\",\"formatter\":{\"id\":\"2379\"},\"major_label_policy\":{\"id\":\"2381\"},\"ticker\":{\"id\":\"2359\"}},\"id\":\"2358\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"2409\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"2406\",\"type\":\"DaysTicker\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"2407\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"2416\"},{\"id\":\"2450\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"2415\",\"type\":\"Legend\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"2408\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"2356\",\"type\":\"LinearScale\"},{\"attributes\":{\"end\":13834.904271979689,\"reset_end\":13834.904271979689,\"reset_start\":2775.4162842234373,\"start\":2775.4162842234373,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"2346\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"BTC Price\",\"formatter\":{\"id\":\"2382\"},\"major_label_policy\":{\"id\":\"2384\"},\"ticker\":{\"id\":\"2363\"}},\"id\":\"2362\",\"type\":\"LinearAxis\"},{\"attributes\":{\"end\":1564358400000.0,\"reset_end\":1564358400000.0,\"reset_start\":1550620800000.0,\"start\":1550620800000.0,\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"2345\",\"type\":\"Range1d\"},{\"attributes\":{\"axis\":{\"id\":\"2358\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"2361\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"2386\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"2447\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2423\",\"type\":\"Line\"},{\"attributes\":{\"data\":{\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"gpV2RcUHd0Vxs3hFiQt4RZANeUWjhnlFsbR4RRwKd0WbUHRFksFwRTBRb0UWR25FU/dsReFqbEVo6WxF8jBvRVXKdUU9n3hFy755RT1nekV3lHpFwfl6RWV7ekUcAnpFKnx3RVLBdEUTBXNFIDVzRZsjc0VhL3NF8i5zRaiCc0WEw3NFInJzRRvNckVJ7HFF5rZwRWUOcEUSoG9Fc9NvRaPccEXoAXRFps92RddDeEWbZXhF21B4RVUqd0Vt8XVF3EZ1RdCCdEW4PnRFvadzRdCEc0UnmXJFisFyRTDqcUWKCXFFXZdwRTQOcUV60nFFJudyRTsHdEVYqHVF+Bx0RYP5dEUgb3RFx4d0RUzackUAq3FFqWZwRSHFbkXLYW1F8epsRUJ8bUVCTHFF2bx2RfQ2e0UqyXpFSR16RWWTeEUSLHdFVLF1RcwwdUV2enRFP890RYFSdUU2yHVF7jl1Rd0ldUV2Z3RFg91zRRZqc0UWL3NFZfByRQTjckXs83JFbjxzRcGUc0WUUHNF0TlzRcFrc0Vu/nNFWQ50RSULdEW6mnNFqwtzRQFIckXqenBFK1VuRV+8a0VX9WpFuutsRZXVbkUOunJF/zF4RR7VfkX7Yn5FHZN6Rc5zeEVIzHVF2vV2RfTId0VjsXZFvJZ2RekjdkWyp3VFTCZ1RVrudEW++3RF2j91Ra4wdUUC9HRFcpx0RTs1dEW3l3NFSiZzRdqlckW8dnJFYRpzRak0dEWxoXNFCwR0RQ3kdEVsl3RFhUdzRQLockXKfXJFaVtwRcXgbUVBA2pFpRBnRX18Z0UA82xFtkNzRVOsckUpLn5FLDWERSCNf0X2Yn1F7+t2RQ==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[160]}},\"selected\":{\"id\":\"2419\"},\"selection_policy\":{\"id\":\"2447\"}},\"id\":\"2418\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"2404\",\"type\":\"DaysTicker\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"2410\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"2363\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2389\",\"type\":\"Line\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"2403\",\"type\":\"DaysTicker\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"2347\"},{\"id\":\"2366\"},{\"id\":\"2367\"},{\"id\":\"2368\"},{\"id\":\"2369\"},{\"id\":\"2370\"}]},\"id\":\"2372\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"2362\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"2365\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"2385\"},\"glyph\":{\"id\":\"2388\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"2390\"},\"nonselection_glyph\":{\"id\":\"2389\"},\"selection_glyph\":{\"id\":\"2417\"},\"view\":{\"id\":\"2392\"}},\"id\":\"2391\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2421\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"2422\",\"type\":\"Line\"},{\"attributes\":{\"below\":[{\"id\":\"2358\"}],\"center\":[{\"id\":\"2361\"},{\"id\":\"2365\"}],\"height\":300,\"left\":[{\"id\":\"2362\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"2391\"},{\"id\":\"2424\"}],\"right\":[{\"id\":\"2415\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"2350\"},\"toolbar\":{\"id\":\"2372\"},\"width\":700,\"x_range\":{\"id\":\"2345\"},\"x_scale\":{\"id\":\"2354\"},\"y_range\":{\"id\":\"2346\"},\"y_scale\":{\"id\":\"2356\"}},\"id\":\"2349\",\"subtype\":\"Figure\",\"type\":\"Plot\"}],\"root_ids\":[\"2343\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.2\"}};\n",
       "    var render_items = [{\"docid\":\"bd04279c-3440-41a4-b074-6fec693c2688\",\"root_ids\":[\"2343\"],\"roots\":{\"2343\":\"fda60cc3-ae13-493d-ae90-88b043bcc130\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [index]   (value)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "2343"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "# YOUR CODE HERE!\n",
    "stocks.hvplot(\n",
    "    xlabel='Monthly Progression',\n",
    "    ylabel='BTC Price',\n",
    "    title='Actual vs Predicted Bitcoin Prices Fear and Greed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL ANALYSIS:**\n",
    "\n",
    "Poor model. Sentiment cannot predict prices.\n",
    "\n",
    "The idea behind this model is that it is using **sentiment** of Bitcoin, to predict the closing price of Bitcoin. We're using the FNG index to get sentiment scores. Most BTC buyers are getting their sentiment and impressions of the Bitcoin asset from forum sites like reddit, 4chan, or Elon Musk's Twitter account, I do not think the FNG reflects those sources.\n",
    "\n",
    "Bitcoin had a serious crash in 2018, and likely the senitment around Bitcoin would be mostly negative (from serious fundamental investors). And likely negative sentiment will cause the model to predict BTC prices to be low. Not to mention most BTC buyers are getting their sentiment and impressions of the Bitcoin asset from forum sites like reddit, 4chan, or Elon Musk's Twitter account. \n",
    "\n",
    "Back to the model.\n",
    "\n",
    "The FNG is very poor predicting ability for our model. Real prices outpaced predicted from April to the rest of our window.  One of the key takeaways is the number of predictions being made each month (See below cell). In Feb the model is making 9 predictions, but then in March it vastly increases to 31 and for the subsequent months. Also, from earlier the model summary there seems to be an isufficient number of params to descibe the model. The model kept increasing params to use at each LSTM layer, and not dropping out anything. We could add more layers, but the core problem is that there just isn't enough parameters. We need more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Real  Predicted\n",
       "2     9          9\n",
       "3    31         31\n",
       "4    30         30\n",
       "5    31         31\n",
       "6    30         30\n",
       "7    29         29"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying number of predictions being made by the model.\n",
    "stocks.groupby(stocks.index.month).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:ml2env] *",
   "language": "python",
   "name": "conda-env-ml2env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
