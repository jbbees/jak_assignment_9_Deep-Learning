{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin closing prices to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape                        # 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape                        # 1 target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "# YOUR CODE HERE!\n",
    "split = int(0.7 * len(X))    # this defines the split of 70% of the entire length of the X data. X has 532 datapoints, so the first 372 datapoints will be assigned to training.\n",
    "X_train = X[: split]         # this takes the whole X dataset (532 datapoints) from index numbers 0-371 and assigns to the training. It applies the split at index number 372, so anything from that index is not included in the training. \n",
    "X_test = X[split: ]          # Any X data from index number 372 and onward is assigned to test.                 \n",
    "y_train = y[: split]\n",
    "y_test = y[split : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# CODER'S Note: Using SOlUTIONS cell for this segment, my original cell was not scaling the data between 0-1, and giving me vertical vectors of 3600, 3700, etc. These high values cannot be used for the model.\n",
    "\n",
    "# Creating 4 MinMaxScaler() objects. \n",
    "X_train_scaler = MinMaxScaler()                         # create a scaler object\n",
    "X_test_scaler = MinMaxScaler()\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_test_scaler = MinMaxScaler()\n",
    "\n",
    "# fitting the train data\n",
    "X_train_scaler.fit(X_train)                               # fit each scaler objects with the appropriate X,y train/test datasets\n",
    "y_train_scaler.fit(y_train)\n",
    "X_test_scaler.fit(X_test)\n",
    "y_test_scaler.fit(y_test)\n",
    "\n",
    "# transform the data from raw form to scaled form. \n",
    "X_train = X_train_scaler.transform(X_train)               # transform each X,y dataset into normalized values between 0-1. assign our scaler objects that are fitted with the raw dataset, and transform is run on those values. \n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "X_test = X_test_scaler.transform(X_test)\n",
    "y_test = y_test_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.01034043]\n",
      "  [0.00242586]\n",
      "  [0.00307681]\n",
      "  [0.00183924]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01974407]]\n",
      "\n",
      " [[0.00242586]\n",
      "  [0.00307681]\n",
      "  [0.00183924]\n",
      "  [0.        ]\n",
      "  [0.00051155]\n",
      "  [0.00254834]\n",
      "  [0.00577449]\n",
      "  [0.        ]\n",
      "  [0.02614593]\n",
      "  [0.02101502]]\n",
      "\n",
      " [[0.00307681]\n",
      "  [0.00183924]\n",
      "  [0.        ]\n",
      "  [0.00051155]\n",
      "  [0.00305859]\n",
      "  [0.00830812]\n",
      "  [0.00577449]\n",
      "  [0.02614593]\n",
      "  [0.02740859]\n",
      "  [0.02643977]]\n",
      "\n",
      " [[0.00183924]\n",
      "  [0.        ]\n",
      "  [0.00051155]\n",
      "  [0.00305859]\n",
      "  [0.00881542]\n",
      "  [0.00830812]\n",
      "  [0.03176945]\n",
      "  [0.02740859]\n",
      "  [0.03279791]\n",
      "  [0.02240906]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.00051155]\n",
      "  [0.00305859]\n",
      "  [0.00881542]\n",
      "  [0.00881542]\n",
      "  [0.03423683]\n",
      "  [0.03302481]\n",
      "  [0.03279791]\n",
      "  [0.02879352]\n",
      "  [0.02747223]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "# YOUR CODE HERE!\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))           # we do this because LSTM needs the features to be in a vertical vector. \n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "print(X_test[:5])       # Features values are normalized/scaled between 0-1, presented in a vertical vector.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "# YOUR CODE HERE!\n",
    "model = Sequential ()                            # build the RNN model\n",
    "\n",
    "number_units = 30                                # \n",
    "dropout_fraction = 0.2                           # set the dropout rate to 20%, so after running through each layer, it keeps 80% of the data. \n",
    "\n",
    "# layer 1\n",
    "\n",
    "model.add(LSTM(                                  # Define an LSTM layer. \n",
    "    units = number_units,                        # passing the units\n",
    "    return_sequences =  True,                    # return sequences = True to connect to the next LSTM layer.\n",
    "    input_shape = (X_train.shape[1], 1)          # X_train.shape[1] is number of time steps, 10 days worth of prices. The second 1 is number of input features it will use to predict 11th day price. \n",
    "))\n",
    "\n",
    "model.add(Dropout(dropout_fraction))              # add first dropout layer, drops 20% \n",
    "\n",
    "# layer 2\n",
    "\n",
    "model.add(LSTM(                                  # Make another LSTM layer.\n",
    "    units = number_units,                          \n",
    "    return_sequences = True                      # return_sequences =True to connect to the next LSTM layer. \n",
    "))\n",
    "\n",
    "model.add(Dropout(dropout_fraction))             # 2nd dropout layer, drops another 20% \n",
    "\n",
    "# layer 3\n",
    "\n",
    "model.add(LSTM(units=number_units))               # Define final LSTM layer. Only need to pass units param in 3rd LSTM layer\n",
    "                                                  # No need to add a return_sequences param, no other LSTM will be added.\n",
    "\n",
    "model.add(Dropout(dropout_fraction))              # dropout layer, drops 20%\n",
    "\n",
    "# output layer \n",
    "model.add(Dense(1))                               # Dense output layer that should return only 1 final value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE!\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "# YOUR CODE HERE!\n",
    "model.summary()  \n",
    "\n",
    "# 18,511 parameters. \n",
    "# All defined 3 LSTM layers, and 3 Droput layers are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "372/372 [==============================] - 12s 4ms/step - loss: 0.0276\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0238\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0287\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0286\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0241\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0221A: 0s - \n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0223\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0188\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 2s 4ms/step - loss: 0.0200\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x264857ee848>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)   # when working with Time Series data in NN's you have to set shuffle = False, otherwisw it will not be looking at the sequential data.\n",
    "\n",
    "# CODER'S NOTE: Loss function begins at .0276 but adter 10 epoch is lowered to .0191, not that great of a decline, woud optimally like to see a loss close to .00191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 2ms/step - loss: 0.0534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05337952449917793"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# YOUR CODE HERE!\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "# YOUR CODE HERE!\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = y_test_scaler.inverse_transform(predicted)\n",
    "real_prices = y_test_scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>9772.139648</td>\n",
       "      <td>7155.851074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>9882.429688</td>\n",
       "      <td>7135.718262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>9847.450195</td>\n",
       "      <td>7106.458496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>9478.320313</td>\n",
       "      <td>7080.506836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>9531.769531</td>\n",
       "      <td>7044.298828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Real    Predicted\n",
       "2019-07-25  9772.139648  7155.851074\n",
       "2019-07-26  9882.429688  7135.718262\n",
       "2019-07-27  9847.450195  7106.458496\n",
       "2019-07-28  9478.320313  7080.506836\n",
       "2019-07-29  9531.769531  7044.298828"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='5919'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"83b38fb9-506e-4abb-b76f-18a676cbf978\" data-root-id=\"5919\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"a3b9ef37-30a0-4aff-bbfe-42a8b36976af\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"6027\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5997\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5943\",\"type\":\"PanTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5965\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5946\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"5962\",\"type\":\"Selection\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"5981\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"5944\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"6000\"}]},\"id\":\"6026\",\"type\":\"LegendItem\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"5989\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"5930\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"5947\"}},\"id\":\"5945\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"5995\",\"type\":\"Selection\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"5982\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"5957\",\"type\":\"AllLabels\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"5987\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"source\":{\"id\":\"5994\"}},\"id\":\"6001\",\"type\":\"CDSView\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"5988\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"5979\"},{\"id\":\"5980\"},{\"id\":\"5981\"},{\"id\":\"5982\"},{\"id\":\"5983\"},{\"id\":\"5984\"},{\"id\":\"5985\"},{\"id\":\"5986\"},{\"id\":\"5987\"},{\"id\":\"5988\"},{\"id\":\"5989\"},{\"id\":\"5990\"}]},\"id\":\"5935\",\"type\":\"DatetimeTicker\"},{\"attributes\":{\"data\":{\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"vCL433qorkBmxAWgGQyvQCHn/X8Uwq5A3gn2Xw8fr0C+MQQAFzWwQGS1+X89d61ARN0HIAULrkCcSgaAwtOtQCP2CaBw7a1AZLX5f73erUB3RfC/9e6tQFZe8j/hBa5AqqENwJ7IrUDdCfZfjyatQAIPDCBcRK5Ad0Xwv/VFrkAg2PFfOFWuQIm6D0AKOK5AvCL433rXrkCHqwMgrrOuQOEnDqDHRa5A/vDz3yNhrkBWXvI/4UyuQFZe8j/hUq5AQs77/yiurkBE3QcgBXavQAAAAAAAPK9AyogLQLMpr0DgJw6gR3CvQAAAAACAsa9AAg8MINw5r0CHqwMgrkGvQN8YAoBrTq9AH9jxXzg0r0BmxAWgGamuQCP2CaBwzK5Ad0Xwv/Wbr0CaO/pf5oivQE4lA0BhD7BATiUDQCEWsEArL/mfsBCwQHpU/N9RN7BAhqsDIO4qs0C+MQQAl3CzQAtI+x9cMbNAvSL43zq3s0ABAAAAQMGzQELO+/8oUbRAvjEEABeutEAtPgXATFG0QGXEBaCZxrRA1dAGYI+4s0AAAAAAgNmzQELO+/+o2LNAvjEEAJcttEBE3QcgRa2zQNXQBmDPXLRAm0oGgEJ0tED/////v6m0QOlg/Z+Hr7RAhasDIC7OtEBktfl/vbm0QN8YAoCrErVAZcQFoBmjtUAh5/1/lE61QN8YAoCrKrRAvjEEABdytEC8Ivjfem20QNPB+j9zmLRAbwwBwPV1tED1twTgo+a0QJHz/j+KDbVAF58CYLh8tUBOJQNAYXm2QCHn/X8U0LZA9bcE4COitkDfGAKAK3S2QHlU/N+Ru7ZAbwwBwLVut0BvDAHA9Ru4QJHz/j9K1rhACkj7H1wXvEBPJQNAoUG7QApI+x9cfr5ATSUDQCEsv0Ah5/1/1Pe/QApI+x8cwr5AbgwBwPXLvEAh5/1/FGK8QHpU/N+RAMBAkfP+P0o+v0CHqwMg7gu/QPa3BODjyr1A/////3/EvkCaO/pfZjy/QE4lA0Ahe79A3xgCgB0LwUBvDAHAlSjBQLLa/L9sB8FA6WD9n0fswEAAAAAAICrAQG8MAcBVs8BAWW3+X++1wEAh5/1/9BDBQGS1+X99sr9AF58CYHj9vUCR8/4/Sm++QApI+x9cf75ATiUDQKFCv0DpYP2fx/2+QCsv+Z9w271AAAAAAABVv0B5VPzfUe2+QPa3BOAj7r9AvjEEAMkVwEA4hgDg+vrAQOlg/Z/HSsFAvjEEAJeJwUBOJQNAATzCQDiGAODavMFAyHn/H0UgwkCy2vy/bKDCQFlt/l9v9cNAyHn/H8XgxECy2vy//jPFQLLa/L/ejcVA3xgCgCvuxkB7VPzfozjJQN8YAoALycVA6WD9n4chyECy2vy/DDbHQBefAmCGCMVAWW3+X++vxECnkgGgEC7FQIarAyDOZsdAIef9f0LKxUAAAAAAoHjFQBefAmB4+MVAelT83yNpxkAg5/1/FATIQCHn/X+Ci8hAWW3+X4+hx0Babf5fjyfGQFlt/l+vCsdAhqsDIPwxxkAh5/1/NO7DQE4lA0AhMcVAF58CYLhnwkBOJQNAE/DCQLLa/L8sx8RAF58CYHiSxEBwDAHAtQPFQDiGAOBarcRAWW3+X+8qxEBOJQNAEz/DQHpU/N8RFsNAvjEEADdNw0DqYP2fuTvDQL4xBAApg8JAIef9f+KdwkA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]}},\"selected\":{\"id\":\"5962\"},\"selection_policy\":{\"id\":\"5977\"}},\"id\":\"5961\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"end\":1564358400000.0,\"reset_end\":1564358400000.0,\"reset_start\":1550620800000.0,\"start\":1550620800000.0,\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"5921\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"5932\",\"type\":\"LinearScale\"},{\"attributes\":{\"data\":{\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"jLOCRdtvg0UlV4RFlTWFRZ/6hUWIy4ZFjC+HRVMwh0Xg6YZF3IOGRfIfhkV+zoVFMZmFRVBzhUVMQYVFmjOFRRlAhUWFZIVF5Y6FRWXNhUX+E4ZFvEaGRWtjhkV0aoZFO2CGRZ9fhkW5iYZFG8+GRY4Yh0WIZYdF47eHRWn0h0W+FohFkSSIRTAhiEVJ/4dFpc6HRYK5h0UJw4dFkPiHRdNOiEVwrYhFOg+JRYNQikUga4xFKtGORYE1kUXmWpNFN0WVRYL/lkUSXJhF1XGZRc30mUU4CJpFyN2ZRa+umUU0aJlFtkeZRaFcmUWFrJlFfR+aRXSkmkU0H5tFLZmbRTM6nEUd25xF1gqdRQDfnEV8gZxFoSGcRV7Jm0UkoZtF2LObRW8SnEVP8pxFs0KeRUCrn0WW3qBF9NqhRZnUokVq+6NF+2ylRbX7p0VdBKtFbfKuRfdss0XYBrhFJNa7RaQUvkV+2r5F3pu/RZxnwEWpF8FF2WDBReh0wUVGrcFFWhnCRV5hw0XvS8VFk03HRUX5yEUB9clF6IzKRbTrykW1RstFjA7LRbLtyUVUPMhFwnjGRcwWxUUeGMRFpivDRayawkXyWMJF4JDCRS0/w0Uhl8RF02vGRSiLyEWz+MpFTSnNRfYaz0V45tBFSirTRfIB1kU4IdlFGC/cRbxr30XRSeNFHwbmRWlb6EXWAupFJHvqRXDm6UXt1OhFEFLoRTvw50W/cedFIwLnRboT50XZu+dFJBnpRbWD6kXvO+tF6ozrRXhe60WNXOpFZQLpReC85kUd+eNFpbnhRVZH4EViyd9F/NvfRWnq30XPnt9Fv/3eRasT3kUORN1FZCLcRQ==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[160]}},\"selected\":{\"id\":\"5995\"},\"selection_policy\":{\"id\":\"6012\"}},\"id\":\"5994\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"5990\",\"type\":\"YearsTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"5994\"},\"glyph\":{\"id\":\"5997\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"5999\"},\"nonselection_glyph\":{\"id\":\"5998\"},\"selection_glyph\":{\"id\":\"6027\"},\"view\":{\"id\":\"6001\"}},\"id\":\"6000\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5999\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5942\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"5961\"},\"glyph\":{\"id\":\"5964\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"5966\"},\"nonselection_glyph\":{\"id\":\"5965\"},\"selection_glyph\":{\"id\":\"5993\"},\"view\":{\"id\":\"5968\"}},\"id\":\"5967\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis_label\":\"Monthly Progression\",\"formatter\":{\"id\":\"5955\"},\"major_label_policy\":{\"id\":\"5957\"},\"ticker\":{\"id\":\"5935\"}},\"id\":\"5934\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"5979\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"5992\"},{\"id\":\"6026\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"5991\",\"type\":\"Legend\"},{\"attributes\":{\"axis_label\":\"BTC Price\",\"formatter\":{\"id\":\"5958\"},\"major_label_policy\":{\"id\":\"5960\"},\"ticker\":{\"id\":\"5939\"}},\"id\":\"5938\",\"type\":\"LinearAxis\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"5980\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"axis\":{\"id\":\"5934\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"5937\",\"type\":\"Grid\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#fc4f30\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5998\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"5967\"}]},\"id\":\"5992\",\"type\":\"LegendItem\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"5985\",\"type\":\"DaysTicker\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5964\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6012\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"5984\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"5939\",\"type\":\"BasicTicker\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"5983\",\"type\":\"DaysTicker\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer06561\",\"sizing_mode\":\"stretch_width\"},\"id\":\"6244\",\"type\":\"Spacer\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"5923\"},{\"id\":\"5942\"},{\"id\":\"5943\"},{\"id\":\"5944\"},{\"id\":\"5945\"},{\"id\":\"5946\"}]},\"id\":\"5948\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"5938\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"5941\",\"type\":\"Grid\"},{\"attributes\":{\"end\":13831.480297400003,\"reset_end\":13831.480297400003,\"reset_start\":2813.0800045999995,\"start\":2813.0800045999995,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"5922\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"5958\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"5977\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"5986\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{index}\":\"datetime\"},\"renderers\":[{\"id\":\"5967\"},{\"id\":\"6000\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"index\",\"@{index}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"5923\",\"type\":\"HoverTool\"},{\"attributes\":{\"text\":\"Actual vs Predicted Bitcoin Closing Prices\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"5926\",\"type\":\"Title\"},{\"attributes\":{\"children\":[{\"id\":\"5920\"},{\"id\":\"5925\"},{\"id\":\"6244\"}],\"margin\":[0,0,0,0],\"name\":\"Row06556\",\"tags\":[\"embedded\"]},\"id\":\"5919\",\"type\":\"Row\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"5947\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5993\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"5961\"}},\"id\":\"5968\",\"type\":\"CDSView\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer06560\",\"sizing_mode\":\"stretch_width\"},\"id\":\"5920\",\"type\":\"Spacer\"},{\"attributes\":{},\"id\":\"5960\",\"type\":\"AllLabels\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#30a2da\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"5966\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5955\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"below\":[{\"id\":\"5934\"}],\"center\":[{\"id\":\"5937\"},{\"id\":\"5941\"}],\"height\":300,\"left\":[{\"id\":\"5938\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"5967\"},{\"id\":\"6000\"}],\"right\":[{\"id\":\"5991\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"5926\"},\"toolbar\":{\"id\":\"5948\"},\"width\":700,\"x_range\":{\"id\":\"5921\"},\"x_scale\":{\"id\":\"5930\"},\"y_range\":{\"id\":\"5922\"},\"y_scale\":{\"id\":\"5932\"}},\"id\":\"5925\",\"subtype\":\"Figure\",\"type\":\"Plot\"}],\"root_ids\":[\"5919\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.2\"}};\n",
       "    var render_items = [{\"docid\":\"a3b9ef37-30a0-4aff-bbfe-42a8b36976af\",\"root_ids\":[\"5919\"],\"roots\":{\"5919\":\"83b38fb9-506e-4abb-b76f-18a676cbf978\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [index]   (value)"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "5919"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "# YOUR CODE HERE!\n",
    "stocks.hvplot(\n",
    "    xlabel='Monthly Progression',\n",
    "    ylabel='BTC Price',\n",
    "    title='Actual vs Predicted Bitcoin Closing Prices'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL ANALYSIS:** \n",
    "\n",
    "Predicting closing prices on Bitcoin is not useful here. BTC prices are too volatile for a model to predict. it might be better to predict based on percent change of price of BTC.\n",
    "\n",
    "One thing to take into consideration when it comes to closing price is that Bitcoin isn't trading based on stock market market time. When it turns 4pm, whatever the price a stock is at, that's the closing price. BTC is traded at all hours of the day, so what is considered a closing price, I assume it's 11:59pm. And it's traded on weekends and holidays. So there is a lot data generated throughout the day to arrive at a closing price. \n",
    "\n",
    "Bitcoin in this case, which is prone to huge price fluctuations each day. Building a model to predict on prices alone, most likely will predict the closing price for a target day, to be in line with the closing price of the previous day. So we see in the beginning of our time window predictions have a slow upward trend. BTC crashed in 2018, many small investors lost a lot, so it is not surprising actual prices were below predicted. Investors skeptical to get back in the BTC market withheld investing. But Bitcoin enthusiasm increased and ralied mid-2019, but predictions stayed in par with the slow price trends. \n",
    "\n",
    "Just look at the tail end of our allotted window in year 2019. Huge uptick in actual BTC prices, some spikiness and little selloffs at the peak in July 2019, but predictions are much more in line of a slow trend from early part of the time window. The predicitons are using the previous day closing prices from that time to predict a similar closing price for the next day, but that's not how BTC prices actually behave on any given day. Actual BTC prices are well above the predicted values by a difference of 2300. This is because Bitcoin only was just recovering from the 2018 global crash from mass investor selloff taking profits, and this led to optimistic buyers to re-invest in Bitcoin throughout 2019, buying in at the lower dip, raising the prices. Plus, Bitcoin can bought at any time. It does not operate like the stock martket where you can only execute trade orders when the US market is open. And there's limitation as to who in the world can buy into Bitcoin worldwide. "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:ml2env] *",
   "language": "python",
   "name": "conda-env-ml2env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
